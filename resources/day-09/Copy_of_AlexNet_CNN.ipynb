{"cells":[{"cell_type":"code","execution_count":1,"id":"0cb3b8c4","metadata":{"id":"0cb3b8c4","executionInfo":{"status":"ok","timestamp":1651053822988,"user_tz":-300,"elapsed":3636,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import Flatten\n","from keras. layers import MaxPooling2D\n","from keras.layers import Dense\n","import numpy as np\n","#import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import os\n","import time"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8LhuEElW-Fq","outputId":"28783065-eaf7-47cb-d38b-32609dcb1537","executionInfo":{"status":"ok","timestamp":1651053841091,"user_tz":-300,"elapsed":16031,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"id":"s8LhuEElW-Fq","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["AlexNet consists of 5 Convolutional Layers and 3 Fully Connected Layers. In Convolutional Neural Networks, Filters detect spatial patterns such as edges in an image by detecting the changes in intensity values of the image. valid\" means no padding. \"same\" results in padding with zeros"],"metadata":{"id":"EXyC2U7LzDRl"},"id":"EXyC2U7LzDRl"},{"cell_type":"markdown","source":["filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n","\n","kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window\n","\n","strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width.\n","\n"],"metadata":{"id":"fRMdaP6M2d7s"},"id":"fRMdaP6M2d7s"},{"cell_type":"code","execution_count":4,"id":"afa72d60","metadata":{"id":"afa72d60","executionInfo":{"status":"ok","timestamp":1651053927331,"user_tz":-300,"elapsed":338,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[],"source":["model=keras.models.Sequential([\n","    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPool2D(pool_size=(2,2)),\n","    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPool2D(pool_size=(3,3)),\n","    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.MaxPool2D(pool_size=(2,2)),\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(1024,activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(1024,activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(1,activation='softmax')  \n","])"]},{"cell_type":"code","execution_count":5,"id":"c6dddd2e","metadata":{"id":"c6dddd2e","executionInfo":{"status":"ok","timestamp":1651053931088,"user_tz":-300,"elapsed":4,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","model.compile(optimizer='adadelta',loss='binary_crossentropy',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":6,"id":"31e1f6bf","metadata":{"id":"31e1f6bf","executionInfo":{"status":"ok","timestamp":1651053934915,"user_tz":-300,"elapsed":333,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[],"source":["train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.4,horizontal_flip = True)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n"]},{"cell_type":"code","execution_count":7,"id":"d3e65e10","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3e65e10","outputId":"b47031ab-30ce-4483-8064-cfc944aa5cde","executionInfo":{"status":"ok","timestamp":1651053976774,"user_tz":-300,"elapsed":1390,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 238 images belonging to 2 classes.\n","Found 39 images belonging to 2 classes.\n"]}],"source":["training_set =train_datagen.flow_from_directory('/content/drive/MyDrive/deep_learning_bootcamp/day9/train',target_size = (64, 64),batch_size = 32,class_mode = 'binary')\n","test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/deep_learning_bootcamp/day9/test',target_size = (64, 64),batch_size = 32,class_mode = 'binary')"]},{"cell_type":"code","execution_count":8,"id":"61118a23","metadata":{"id":"61118a23","outputId":"33c00844-0734-48d7-c3d4-e101acb91787","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651053979727,"user_tz":-300,"elapsed":343,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["keras.preprocessing.image.DirectoryIterator"]},"metadata":{},"execution_count":8}],"source":["type(training_set)"]},{"cell_type":"code","execution_count":9,"id":"bab5fa16","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bab5fa16","outputId":"9b4466cb-55fa-457f-b9e1-e1dca7230e5d","executionInfo":{"status":"ok","timestamp":1651054290638,"user_tz":-300,"elapsed":309210,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","8/8 [==============================] - 24s 3s/step - loss: 0.8280 - accuracy: 0.5378 - val_loss: 0.6910 - val_accuracy: 0.7500\n","Epoch 2/50\n","8/8 [==============================] - 5s 599ms/step - loss: 0.8918 - accuracy: 0.5378 - val_loss: 0.6889 - val_accuracy: 0.7812\n","Epoch 3/50\n","8/8 [==============================] - 5s 601ms/step - loss: 0.8328 - accuracy: 0.5378 - val_loss: 0.6889 - val_accuracy: 0.7188\n","Epoch 4/50\n","8/8 [==============================] - 5s 599ms/step - loss: 0.7786 - accuracy: 0.5378 - val_loss: 0.6868 - val_accuracy: 0.7812\n","Epoch 5/50\n","8/8 [==============================] - 5s 646ms/step - loss: 0.7167 - accuracy: 0.5378 - val_loss: 0.6862 - val_accuracy: 0.7812\n","Epoch 6/50\n","8/8 [==============================] - 5s 618ms/step - loss: 0.7998 - accuracy: 0.5378 - val_loss: 0.6844 - val_accuracy: 0.8125\n","Epoch 7/50\n","8/8 [==============================] - 5s 582ms/step - loss: 0.7612 - accuracy: 0.5378 - val_loss: 0.6844 - val_accuracy: 0.7812\n","Epoch 8/50\n","8/8 [==============================] - 5s 591ms/step - loss: 0.7464 - accuracy: 0.5378 - val_loss: 0.6835 - val_accuracy: 0.8125\n","Epoch 9/50\n","8/8 [==============================] - 5s 592ms/step - loss: 0.7968 - accuracy: 0.5378 - val_loss: 0.6848 - val_accuracy: 0.7812\n","Epoch 10/50\n","8/8 [==============================] - 5s 590ms/step - loss: 0.7589 - accuracy: 0.5378 - val_loss: 0.6847 - val_accuracy: 0.7812\n","Epoch 11/50\n","8/8 [==============================] - 5s 590ms/step - loss: 0.7673 - accuracy: 0.5378 - val_loss: 0.6866 - val_accuracy: 0.7188\n","Epoch 12/50\n","8/8 [==============================] - 5s 575ms/step - loss: 0.7428 - accuracy: 0.5378 - val_loss: 0.6861 - val_accuracy: 0.7188\n","Epoch 13/50\n","8/8 [==============================] - 5s 587ms/step - loss: 0.7425 - accuracy: 0.5378 - val_loss: 0.6856 - val_accuracy: 0.7812\n","Epoch 14/50\n","8/8 [==============================] - 5s 583ms/step - loss: 0.7884 - accuracy: 0.5378 - val_loss: 0.6863 - val_accuracy: 0.8125\n","Epoch 15/50\n","8/8 [==============================] - 5s 592ms/step - loss: 0.6851 - accuracy: 0.5378 - val_loss: 0.6879 - val_accuracy: 0.8125\n","Epoch 16/50\n","8/8 [==============================] - 5s 590ms/step - loss: 0.7307 - accuracy: 0.5378 - val_loss: 0.6892 - val_accuracy: 0.7500\n","Epoch 17/50\n","8/8 [==============================] - 5s 593ms/step - loss: 0.7095 - accuracy: 0.5378 - val_loss: 0.6905 - val_accuracy: 0.7812\n","Epoch 18/50\n","8/8 [==============================] - 5s 599ms/step - loss: 0.7708 - accuracy: 0.5378 - val_loss: 0.6897 - val_accuracy: 0.7812\n","Epoch 19/50\n","8/8 [==============================] - 5s 591ms/step - loss: 0.6715 - accuracy: 0.5378 - val_loss: 0.6916 - val_accuracy: 0.7812\n","Epoch 20/50\n","8/8 [==============================] - 5s 593ms/step - loss: 0.8018 - accuracy: 0.5378 - val_loss: 0.6933 - val_accuracy: 0.7500\n","Epoch 21/50\n","8/8 [==============================] - 5s 591ms/step - loss: 0.7208 - accuracy: 0.5378 - val_loss: 0.6943 - val_accuracy: 0.7812\n","Epoch 22/50\n","8/8 [==============================] - 5s 597ms/step - loss: 0.6662 - accuracy: 0.5378 - val_loss: 0.6960 - val_accuracy: 0.8125\n","Epoch 23/50\n","8/8 [==============================] - 5s 655ms/step - loss: 0.7324 - accuracy: 0.5378 - val_loss: 0.6985 - val_accuracy: 0.7188\n","Epoch 24/50\n","8/8 [==============================] - 5s 663ms/step - loss: 0.6642 - accuracy: 0.5378 - val_loss: 0.7002 - val_accuracy: 0.7812\n","Epoch 25/50\n","8/8 [==============================] - 5s 597ms/step - loss: 0.7030 - accuracy: 0.5378 - val_loss: 0.7023 - val_accuracy: 0.7812\n","Epoch 26/50\n","8/8 [==============================] - 5s 592ms/step - loss: 0.6878 - accuracy: 0.5378 - val_loss: 0.7051 - val_accuracy: 0.7812\n","Epoch 27/50\n","8/8 [==============================] - 5s 595ms/step - loss: 0.6914 - accuracy: 0.5378 - val_loss: 0.7082 - val_accuracy: 0.7500\n","Epoch 28/50\n","8/8 [==============================] - 5s 605ms/step - loss: 0.7332 - accuracy: 0.5378 - val_loss: 0.7149 - val_accuracy: 0.8125\n","Epoch 29/50\n","8/8 [==============================] - 5s 595ms/step - loss: 0.6752 - accuracy: 0.5378 - val_loss: 0.7094 - val_accuracy: 0.7188\n","Epoch 30/50\n","8/8 [==============================] - 5s 602ms/step - loss: 0.7282 - accuracy: 0.5378 - val_loss: 0.7147 - val_accuracy: 0.7500\n","Epoch 31/50\n","8/8 [==============================] - 5s 653ms/step - loss: 0.6989 - accuracy: 0.5378 - val_loss: 0.7208 - val_accuracy: 0.7812\n","Epoch 32/50\n","8/8 [==============================] - 5s 605ms/step - loss: 0.6692 - accuracy: 0.5378 - val_loss: 0.7317 - val_accuracy: 0.8438\n","Epoch 33/50\n","8/8 [==============================] - 5s 666ms/step - loss: 0.6063 - accuracy: 0.5378 - val_loss: 0.7230 - val_accuracy: 0.7500\n","Epoch 34/50\n","8/8 [==============================] - 5s 591ms/step - loss: 0.6358 - accuracy: 0.5378 - val_loss: 0.7255 - val_accuracy: 0.7500\n","Epoch 35/50\n","8/8 [==============================] - 5s 608ms/step - loss: 0.6748 - accuracy: 0.5378 - val_loss: 0.7313 - val_accuracy: 0.7812\n","Epoch 36/50\n","8/8 [==============================] - 5s 602ms/step - loss: 0.6666 - accuracy: 0.5378 - val_loss: 0.7311 - val_accuracy: 0.7500\n","Epoch 37/50\n","8/8 [==============================] - 5s 599ms/step - loss: 0.6100 - accuracy: 0.5378 - val_loss: 0.7507 - val_accuracy: 0.8750\n","Epoch 38/50\n","8/8 [==============================] - 5s 601ms/step - loss: 0.6064 - accuracy: 0.5378 - val_loss: 0.7297 - val_accuracy: 0.7188\n","Epoch 39/50\n","8/8 [==============================] - 5s 594ms/step - loss: 0.5614 - accuracy: 0.5378 - val_loss: 0.7296 - val_accuracy: 0.7188\n","Epoch 40/50\n","8/8 [==============================] - 5s 594ms/step - loss: 0.6486 - accuracy: 0.5378 - val_loss: 0.7301 - val_accuracy: 0.7188\n","Epoch 41/50\n","8/8 [==============================] - 5s 601ms/step - loss: 0.6149 - accuracy: 0.5378 - val_loss: 0.7475 - val_accuracy: 0.8125\n","Epoch 42/50\n","8/8 [==============================] - 5s 598ms/step - loss: 0.5796 - accuracy: 0.5378 - val_loss: 0.7503 - val_accuracy: 0.7500\n","Epoch 43/50\n","8/8 [==============================] - 5s 597ms/step - loss: 0.6238 - accuracy: 0.5378 - val_loss: 0.7561 - val_accuracy: 0.7812\n","Epoch 44/50\n","8/8 [==============================] - 5s 612ms/step - loss: 0.6511 - accuracy: 0.5378 - val_loss: 0.7528 - val_accuracy: 0.7500\n","Epoch 45/50\n","8/8 [==============================] - 5s 635ms/step - loss: 0.6080 - accuracy: 0.5378 - val_loss: 0.7544 - val_accuracy: 0.7500\n","Epoch 46/50\n","8/8 [==============================] - 5s 623ms/step - loss: 0.6709 - accuracy: 0.5378 - val_loss: 0.7579 - val_accuracy: 0.7500\n","Epoch 47/50\n","8/8 [==============================] - 5s 636ms/step - loss: 0.6246 - accuracy: 0.5378 - val_loss: 0.7524 - val_accuracy: 0.7500\n","Epoch 48/50\n","8/8 [==============================] - 5s 631ms/step - loss: 0.6322 - accuracy: 0.5378 - val_loss: 0.7670 - val_accuracy: 0.7812\n","Epoch 49/50\n","8/8 [==============================] - 5s 644ms/step - loss: 0.5510 - accuracy: 0.5378 - val_loss: 0.7508 - val_accuracy: 0.7188\n","Epoch 50/50\n","8/8 [==============================] - 5s 643ms/step - loss: 0.5664 - accuracy: 0.5378 - val_loss: 0.7551 - val_accuracy: 0.7500\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd427776690>"]},"metadata":{},"execution_count":9}],"source":["model.fit(training_set,epochs = 50,validation_data = test_set,validation_steps = 1)"]},{"cell_type":"code","execution_count":10,"id":"00853439","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"00853439","outputId":"ecde7dad-82fc-4012-e1a5-fd79f9bfcbd0","executionInfo":{"status":"error","timestamp":1651054326285,"user_tz":-300,"elapsed":1008,"user":{"displayName":"1GA19CS165_SHARANRAJ T","userId":"13815582259529713057"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-01697a919ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/FDP_Day4/test/Non Covid/Non_Corona1_134.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/FDP_Day4/test/Non Covid/Non_Corona1_134.jpg'"]}],"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image =image.load_img('/content/drive/MyDrive/FDP_Day4/test/Non Covid/Non_Corona1_134.jpg',target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = model.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'Normal'\n","else:\n","  prediction = 'Corona'\n","print(prediction)\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"4pBuGEQGY2eI"},"id":"4pBuGEQGY2eI","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Copy_of_AlexNet_CNN.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}